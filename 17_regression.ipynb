{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d533bc5e",
   "metadata": {},
   "source": [
    "# Chapter 17: Regression\n",
    "\n",
    "Up to this point, we've been working with classification models, where we try to determine what something is.\n",
    "\n",
    "Now, we're curious about determining a specific value based on an input.\n",
    "\n",
    "Thus, we need a new way to measure loss, and a new output layer activation function.\n",
    "\n",
    "It also means our data are different, we need training data that have  target scalar values, not classes.\n",
    "\n",
    "## 17.1. Linear Activation\n",
    "\n",
    "To predict a scalar value, we use a linear activation function for the output layer.\n",
    "\n",
    "This linear function does not modify its input and passes it to the output:  $y=x$.\n",
    "\n",
    "For the backward pass, we already know the derivative of $f(x)=x$ is $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02761257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear activation\n",
    "class Activation_Linear:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Just remember values\n",
    "        self.inputs = inputs\n",
    "        self.output = inputs\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # derivative is 1, 1 * dvalues = dvalues - the chain rule\n",
    "        self.dinputs = dvalues.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9a6034",
   "metadata": {},
   "source": [
    "This might raise a question — why do we even write some code that does nothing? We just pass inputs to outputs for the forward pass and do the same with gradients during the backward pass since, to apply the chain rule, we multiply incoming gradients by the derivative, which is 1 . We do this only for completeness and clarity to see the activation function of the output layer in the model definition code. From a computational time point of view, this adds almost nothing to the processing time, at least not enough to noticeably impact training times.\n",
    "\n",
    "Now we just need to figure out loss!\n",
    "\n",
    "## 17.2. Mean Squared Error Loss\n",
    "\n",
    "Since we aren’t working with classification labels anymore, we cannot calculate cross-entropy.\n",
    "\n",
    "Two main methods for calculating error in regression are mean squared error (MSE) and mean absolute error (MAE).\n",
    "\n",
    "With mean squared error , you square the difference between the predicted and true values of single outputs (as the model can have multiple regression outputs) and average those squared values.\n",
    "\n",
    "$$\n",
    "L_i = \\frac{1}{J} \\sum_j ( y_{i, \\ j} - \\hat{y}_{i, \\ j} )^2\n",
    "$$\n",
    "\n",
    "$y$ means the target value, $\\hat{y}$ means predicted value, index $i$ means the current sample, index $j$ means the current output in this sample, and the $J$ means the number of outputs.\n",
    "\n",
    "## 17.3. Mean Squared Error Loss Derivative\n",
    "\n",
    "The partial derivative of squared error with respect to the predicted value is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{∂ }{∂ \\hat{y}_{i, \\ j} } L_i &=   \\frac{∂ }{∂ \\hat{y}_{i, \\ j} } \\Big[  \\frac{1}{J} \\sum_j ( y_{i, \\ j} - \\hat{y}_{i, \\ j} )^2 \\Big] =  \\frac{1}{J} \\cdot \\frac{∂ }{∂ \\hat{y}_{i, \\ j} }  ( y_{i, \\ j} - \\hat{y}_{i, \\ j} )^2 \\\\\n",
    "& =  \\frac{1}{J} \\cdot 2 \\cdot ( y_{i, \\ j} - \\hat{y}_{i, \\ j} )^{2-1} \\cdot  \\frac{∂ }{∂ \\hat{y}_{i, \\ j} } [ y_{i, \\ j} - \\hat{y}_{i, \\ j}  ] \\\\\n",
    "& =  \\frac{2}{J} \\cdot ( y_{i, \\ j} - \\hat{y}_{i, \\ j} )^1 \\cdot ( \\frac{∂ }{∂ \\hat{y}_{i, \\ j} }  y_{i, \\ j} - \\frac{∂ }{∂ \\hat{y}_{i, \\ j} }  \\hat{y}_{i, \\ j}  ) = \\frac{2}{J} \\cdot ( y_{i, \\ j} - \\hat{y}_{i, \\ j} ) \\cdot ( 0 - 1 )  \\\\\n",
    "& = \\frac{2}{J} \\cdot ( y_{i, \\ j} - \\hat{y}_{i, \\ j} ) \\cdot ( - 1 ) = - \\frac{2}{J} \\cdot ( y_{i, \\ j} - \\hat{y}_{i, \\ j} )  \\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The partial derivative equals -2 , multiplied by the subtraction of the true and predicted values, and then divided by the number of outputs to normalize the gradients, making their magnitude invariant to the number of outputs.\n",
    "\n",
    "## 17.4. Mean Absolute Error Loss\n",
    "\n",
    "With mean absolute error , you take the absolute difference between the predicted and true values in a single output and average those absolute values:\n",
    "\n",
    "$$\n",
    "L_i = \\frac{1}{J} \\sum_j \\big| y_{i, \\ j} - \\hat{y}_{i, \\ j} \\big|\n",
    "$$\n",
    "\n",
    "$y$ means the target value, $\\hat{y}$ means predicted value, index $i$ means the current sample, index $j$ means the current output in this sample, and the $J$ means the number of outputs.\n",
    "\n",
    "This function, used as a loss, penalizes the error linearly. It produces sparser results and is robust to outliers, which can be both advantageous and disadvantageous. In reality, L1 (MAE) loss is used less frequently than L2 (MSE) loss.\n",
    "\n",
    "## 17.5. Mean Absolute Error Loss Derivative\n",
    "\n",
    "The partial derivative for absolute error with respect to the predicted values is:\n",
    "\n",
    "$$\n",
    "\\begin{alignat}{2}\n",
    "\\frac{∂ }{∂ \\hat{y}_{i, \\ j} } L_i  & = \\frac{∂ }{∂ \\hat{y}_{i, \\ j} } \\Big[ \\frac{1}{J} \\sum_j \\big| y_{i, \\ j} - \\hat{y}_{i, \\ j} \\big| \\Big] \\\\\n",
    "& = \\frac{1}{J} \\cdot \\frac{∂ }{∂ \\hat{y}_{i, \\ j} }  \\big| y_{i, \\ j} - \\hat{y}_{i, \\ j} \\big| \\\\\n",
    "& = \\frac{1}{J} \\cdot  \\begin{cases}\n",
    "1 & \\quad y_{i, \\ j} - \\hat{y}_{i, \\ j} > 0\\\\\n",
    "-1 & \\quad y_{i, \\ j} - \\hat{y}_{i, \\ j} < 0\n",
    "\\end{cases} \\\n",
    "\\end{alignat}\n",
    "$$\n",
    "\n",
    "## 17.6. Accuracy in Regression\n",
    "\n",
    "Now that we’ve got data, an activation function, and a loss calculation for regression, we’d like to measure performance.\n",
    "\n",
    "With cross-entropy, we were able to count the number of matches (situations where the prediction equals the ground truth target), and then divide it by the number of samples to measure the model’s accuracy.\n",
    "\n",
    "With a regression model, we have two problems:\n",
    "\n",
    "1) Each output neuron in the model is a separate output.\n",
    "\n",
    "2) The prediction is a float value, and we can’t simply check if the output value equals the ground truth one, as it most likely won’t — if it differs even slightly, the accuracy will be a 0.\n",
    "\n",
    "## 17.7. Full Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52eb73fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, acc: 0.003, loss: 0.496 (data_loss: 0.496, reg_loss: 0.000), lr: 0.005\n",
      "epoch: 100, acc: 0.017, loss: 0.048 (data_loss: 0.048, reg_loss: 0.000), lr: 0.004549590536851684\n",
      "epoch: 200, acc: 0.242, loss: 0.001 (data_loss: 0.001, reg_loss: 0.000), lr: 0.004170141784820684\n",
      "epoch: 300, acc: 0.786, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.003849114703618168\n",
      "epoch: 400, acc: 0.885, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0035739814152966403\n",
      "epoch: 500, acc: 0.082, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00333555703802535\n",
      "epoch: 600, acc: 0.914, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0031269543464665416\n",
      "epoch: 700, acc: 0.921, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.002942907592701589\n",
      "epoch: 800, acc: 0.086, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0027793218454697055\n",
      "epoch: 900, acc: 0.931, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0026329647182727752\n",
      "epoch: 1000, acc: 0.936, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.002501250625312656\n",
      "epoch: 1100, acc: 0.501, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0023820867079561697\n",
      "epoch: 1200, acc: 0.940, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.002273760800363802\n",
      "epoch: 1300, acc: 0.940, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.002174858634188778\n",
      "epoch: 1400, acc: 0.942, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0020842017507294707\n",
      "epoch: 1500, acc: 0.943, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0020008003201280513\n",
      "epoch: 1600, acc: 0.094, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001923816852635629\n",
      "epoch: 1700, acc: 0.940, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001852537977028529\n",
      "epoch: 1800, acc: 0.944, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0017863522686673815\n",
      "epoch: 1900, acc: 0.065, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0017247326664367024\n",
      "epoch: 2000, acc: 0.947, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0016672224074691564\n",
      "epoch: 2100, acc: 0.941, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0016134236850596968\n",
      "epoch: 2200, acc: 0.706, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0015629884338855893\n",
      "epoch: 2300, acc: 0.943, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0015156107911488332\n",
      "epoch: 2400, acc: 0.946, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0014710208884966167\n",
      "epoch: 2500, acc: 0.925, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0014289797084881396\n",
      "epoch: 2600, acc: 0.947, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.001389274798555154\n",
      "epoch: 2700, acc: 0.951, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0013517166801838335\n",
      "epoch: 2800, acc: 0.948, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0013161358252171624\n",
      "epoch: 2900, acc: 0.951, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0012823800974608873\n",
      "epoch: 3000, acc: 0.951, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0012503125781445363\n",
      "epoch: 3100, acc: 0.948, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0012198097096852891\n",
      "epoch: 3200, acc: 0.948, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0011907597046915933\n",
      "epoch: 3300, acc: 0.950, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0011630611770179114\n",
      "epoch: 3400, acc: 0.952, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0011366219595362584\n",
      "epoch: 3500, acc: 0.953, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0011113580795732384\n",
      "epoch: 3600, acc: 0.954, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0010871928680147858\n",
      "epoch: 3700, acc: 0.953, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0010640561821664183\n",
      "epoch: 3800, acc: 0.953, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0010418837257762034\n",
      "epoch: 3900, acc: 0.953, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0010206164523372118\n",
      "epoch: 4000, acc: 0.954, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0010002000400080014\n",
      "epoch: 4100, acc: 0.952, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0009805844283192783\n",
      "epoch: 4200, acc: 0.932, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0009617234083477593\n",
      "epoch: 4300, acc: 0.228, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0009435742592942063\n",
      "epoch: 4400, acc: 0.959, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0009260974254491572\n",
      "epoch: 4500, acc: 0.955, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0009092562284051646\n",
      "epoch: 4600, acc: 0.944, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.000893016610108948\n",
      "epoch: 4700, acc: 0.955, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0008773469029654326\n",
      "epoch: 4800, acc: 0.953, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.000862217623728229\n",
      "epoch: 4900, acc: 0.953, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0008476012883539582\n",
      "epoch: 5000, acc: 0.960, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0008334722453742291\n",
      "epoch: 5100, acc: 0.958, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0008198065256599442\n",
      "epoch: 5200, acc: 0.959, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0008065817067268914\n",
      "epoch: 5300, acc: 0.960, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0007937767899666614\n",
      "epoch: 5400, acc: 0.960, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0007813720893889669\n",
      "epoch: 5500, acc: 0.960, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0007693491306354824\n",
      "epoch: 5600, acc: 0.960, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0007576905591756327\n",
      "epoch: 5700, acc: 0.319, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0007463800567248844\n",
      "epoch: 5800, acc: 0.963, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0007354022650389764\n",
      "epoch: 5900, acc: 0.968, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0007247427163357008\n",
      "epoch: 6000, acc: 0.956, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.000714387769681383\n",
      "epoch: 6100, acc: 0.963, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0007043245527539089\n",
      "epoch: 6200, acc: 0.962, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006945409084595084\n",
      "epoch: 6300, acc: 0.965, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006850253459377996\n",
      "epoch: 6400, acc: 0.965, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006757669955399379\n",
      "epoch: 6500, acc: 0.964, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006667555674089878\n",
      "epoch: 6600, acc: 0.513, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006579813133307014\n",
      "epoch: 6700, acc: 0.968, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006494349915573451\n",
      "epoch: 6800, acc: 0.972, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006411078343377356\n",
      "epoch: 6900, acc: 0.967, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00063299151791366\n",
      "epoch: 7000, acc: 0.968, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006250781347668457\n",
      "epoch: 7100, acc: 0.967, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006173601679219657\n",
      "epoch: 7200, acc: 0.976, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006098304671301379\n",
      "epoch: 7300, acc: 0.977, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0006024822267743102\n",
      "epoch: 7400, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005953089653530181\n",
      "epoch: 7500, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.000588304506412519\n",
      "epoch: 7600, acc: 0.629, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005814629608093965\n",
      "epoch: 7700, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005747787101965744\n",
      "epoch: 7800, acc: 0.950, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005682463916354131\n",
      "epoch: 7900, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005618608832453085\n",
      "epoch: 8000, acc: 0.972, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00055561729081009\n",
      "epoch: 8100, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005495109352676119\n",
      "epoch: 8200, acc: 0.952, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005435373410153278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8300, acc: 0.979, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005376922249704269\n",
      "epoch: 8400, acc: 0.974, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005319714863283328\n",
      "epoch: 8500, acc: 0.980, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005263711969681019\n",
      "epoch: 8600, acc: 0.978, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005208875924575476\n",
      "epoch: 8700, acc: 0.980, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005155170636148056\n",
      "epoch: 8800, acc: 0.979, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005102561485865905\n",
      "epoch: 8900, acc: 0.981, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005051015254066068\n",
      "epoch: 9000, acc: 0.982, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0005000500050005\n",
      "epoch: 9100, acc: 0.901, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0004950985246063966\n",
      "epoch: 9200, acc: 0.981, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0004902441415825081\n",
      "epoch: 9300, acc: 0.276, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0004854840275754928\n",
      "epoch: 9400, acc: 0.981, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.0004808154630252909\n",
      "epoch: 9500, acc: 0.967, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00047623583198399844\n",
      "epoch: 9600, acc: 0.982, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00047174261722804036\n",
      "epoch: 9700, acc: 0.982, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00046733339564445275\n",
      "epoch: 9800, acc: 0.861, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00046300583387350687\n",
      "epoch: 9900, acc: 0.982, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00045875768419121016\n",
      "epoch: 10000, acc: 0.981, loss: 0.000 (data_loss: 0.000, reg_loss: 0.000), lr: 0.00045458678061641964\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nnfs\n",
    "from nnfs.datasets import sine_data\n",
    "\n",
    "nnfs.init()\n",
    "\n",
    "\n",
    "# Dense layer\n",
    "class Layer_Dense:\n",
    "\n",
    "    # Layer initialization\n",
    "    def __init__(self, n_inputs, n_neurons,\n",
    "                 weight_regularizer_l1=0, weight_regularizer_l2=0,\n",
    "                 bias_regularizer_l1=0, bias_regularizer_l2=0):\n",
    "        # Initialize weights and biases\n",
    "        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "        # Set regularization strength\n",
    "        self.weight_regularizer_l1 = weight_regularizer_l1\n",
    "        self.weight_regularizer_l2 = weight_regularizer_l2\n",
    "        self.bias_regularizer_l1 = bias_regularizer_l1\n",
    "        self.bias_regularizer_l2 = bias_regularizer_l2\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs, weights and biases\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "        # Gradients on regularization\n",
    "        # L1 on weights\n",
    "        if self.weight_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.weights)\n",
    "            dL1[self.weights < 0] = -1\n",
    "            self.dweights += self.weight_regularizer_l1 * dL1\n",
    "        # L2 on weights\n",
    "        if self.weight_regularizer_l2 > 0:\n",
    "            self.dweights += 2 * self.weight_regularizer_l2 * \\\n",
    "                             self.weights\n",
    "        # L1 on biases\n",
    "        if self.bias_regularizer_l1 > 0:\n",
    "            dL1 = np.ones_like(self.biases)\n",
    "            dL1[self.biases < 0] = -1\n",
    "            self.dbiases += self.bias_regularizer_l1 * dL1\n",
    "        # L2 on biases\n",
    "        if self.bias_regularizer_l2 > 0:\n",
    "            self.dbiases += 2 * self.bias_regularizer_l2 * \\\n",
    "                            self.biases\n",
    "\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "\n",
    "# Dropout\n",
    "class Layer_Dropout:\n",
    "\n",
    "    # Init\n",
    "    def __init__(self, rate):\n",
    "        # Store rate, we invert it as for example for dropout\n",
    "        # of 0.1 we need success rate of 0.9\n",
    "        self.rate = 1 - rate\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Save input values\n",
    "        self.inputs = inputs\n",
    "        # Generate and save scaled mask\n",
    "        self.binary_mask = np.random.binomial(1, self.rate,\n",
    "                           size=inputs.shape) / self.rate\n",
    "        # Apply mask to output values\n",
    "        self.output = inputs * self.binary_mask\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradient on values\n",
    "        self.dinputs = dvalues * self.binary_mask\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        # Calculate output values from inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify original variable,\n",
    "        # let's make a copy of values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0] = 0\n",
    "\n",
    "\n",
    "# Softmax activation\n",
    "class Activation_Softmax:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "\n",
    "        # Get unnormalized probabilities\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1,\n",
    "                                            keepdims=True))\n",
    "        # Normalize them for each sample\n",
    "        probabilities = exp_values / np.sum(exp_values, axis=1,\n",
    "                                            keepdims=True)\n",
    "\n",
    "        self.output = probabilities\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "\n",
    "        # Create uninitialized array\n",
    "        self.dinputs = np.empty_like(dvalues)\n",
    "\n",
    "        # Enumerate outputs and gradients\n",
    "        for index, (single_output, single_dvalues) in \\\n",
    "                enumerate(zip(self.output, dvalues)):\n",
    "            # Flatten output array\n",
    "            single_output = single_output.reshape(-1, 1)\n",
    "\n",
    "            # Calculate Jacobian matrix of the output\n",
    "            jacobian_matrix = np.diagflat(single_output) - \\\n",
    "                              np.dot(single_output, single_output.T)\n",
    "            # Calculate sample-wise gradient\n",
    "            # and add it to the array of sample gradients\n",
    "            self.dinputs[index] = np.dot(jacobian_matrix,\n",
    "                                         single_dvalues)\n",
    "\n",
    "\n",
    "# Sigmoid activation\n",
    "class Activation_Sigmoid:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Save input and calculate/save output\n",
    "        # of the sigmoid function\n",
    "        self.inputs = inputs\n",
    "        self.output = 1 / (1 + np.exp(-inputs))\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Derivative - calculates from output of the sigmoid function\n",
    "        self.dinputs = dvalues * (1 - self.output) * self.output\n",
    "\n",
    "\n",
    "# Linear activation\n",
    "class Activation_Linear:\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Just remember values\n",
    "        self.inputs = inputs\n",
    "        self.output = inputs\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # derivative is 1, 1 * dvalues = dvalues - the chain rule\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "\n",
    "# SGD optimizer\n",
    "class Optimizer_SGD:\n",
    "\n",
    "    # Initialize optimizer - set settings,\n",
    "    # learning rate of 1. is default for this optimizer\n",
    "    def __init__(self, learning_rate=1., decay=0., momentum=0.):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.momentum = momentum\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If we use momentum\n",
    "        if self.momentum:\n",
    "\n",
    "            # If layer does not contain momentum arrays, create them\n",
    "            # filled with zeros\n",
    "            if not hasattr(layer, 'weight_momentums'):\n",
    "                layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "                # If there is no momentum array for weights\n",
    "                # The array doesn't exist for biases yet either.\n",
    "                layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "\n",
    "            # Build weight updates with momentum - take previous\n",
    "            # updates multiplied by retain factor and update with\n",
    "            # current gradients\n",
    "            weight_updates = \\\n",
    "                self.momentum * layer.weight_momentums - \\\n",
    "                self.current_learning_rate * layer.dweights\n",
    "            layer.weight_momentums = weight_updates\n",
    "\n",
    "            # Build bias updates\n",
    "            bias_updates = \\\n",
    "                self.momentum * layer.bias_momentums - \\\n",
    "                self.current_learning_rate * layer.dbiases\n",
    "            layer.bias_momentums = bias_updates\n",
    "\n",
    "        # Vanilla SGD updates (as before momentum update)\n",
    "        else:\n",
    "            weight_updates = -self.current_learning_rate * \\\n",
    "                             layer.dweights\n",
    "            bias_updates = -self.current_learning_rate * \\\n",
    "                           layer.dbiases\n",
    "\n",
    "        # Update weights and biases using either\n",
    "        # vanilla or momentum updates\n",
    "        layer.weights += weight_updates\n",
    "        layer.biases += bias_updates\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "\n",
    "# Adagrad optimizer\n",
    "class Optimizer_Adagrad:\n",
    "\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=1., decay=0., epsilon=1e-7):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache += layer.dweights**2\n",
    "        layer.bias_cache += layer.dbiases**2\n",
    "\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * \\\n",
    "                         layer.dweights / \\\n",
    "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * \\\n",
    "                        layer.dbiases / \\\n",
    "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "# RMSprop optimizer\n",
    "class Optimizer_RMSprop:\n",
    "\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
    "                 rho=0.9):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.rho = rho\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.rho * layer.weight_cache + \\\n",
    "            (1 - self.rho) * layer.dweights**2\n",
    "        layer.bias_cache = self.rho * layer.bias_cache + \\\n",
    "            (1 - self.rho) * layer.dbiases**2\n",
    "\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * \\\n",
    "                         layer.dweights / \\\n",
    "                         (np.sqrt(layer.weight_cache) + self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * \\\n",
    "                        layer.dbiases / \\\n",
    "                        (np.sqrt(layer.bias_cache) + self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "\n",
    "# Adam optimizer\n",
    "class Optimizer_Adam:\n",
    "\n",
    "    # Initialize optimizer - set settings\n",
    "    def __init__(self, learning_rate=0.001, decay=0., epsilon=1e-7,\n",
    "                 beta_1=0.9, beta_2=0.999):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.current_learning_rate = learning_rate\n",
    "        self.decay = decay\n",
    "        self.iterations = 0\n",
    "        self.epsilon = epsilon\n",
    "        self.beta_1 = beta_1\n",
    "        self.beta_2 = beta_2\n",
    "\n",
    "    # Call once before any parameter updates\n",
    "    def pre_update_params(self):\n",
    "        if self.decay:\n",
    "            self.current_learning_rate = self.learning_rate * \\\n",
    "                (1. / (1. + self.decay * self.iterations))\n",
    "\n",
    "    # Update parameters\n",
    "    def update_params(self, layer):\n",
    "\n",
    "        # If layer does not contain cache arrays,\n",
    "        # create them filled with zeros\n",
    "        if not hasattr(layer, 'weight_cache'):\n",
    "            layer.weight_momentums = np.zeros_like(layer.weights)\n",
    "            layer.weight_cache = np.zeros_like(layer.weights)\n",
    "            layer.bias_momentums = np.zeros_like(layer.biases)\n",
    "            layer.bias_cache = np.zeros_like(layer.biases)\n",
    "\n",
    "        # Update momentum  with current gradients\n",
    "        layer.weight_momentums = self.beta_1 * \\\n",
    "                                 layer.weight_momentums + \\\n",
    "                                 (1 - self.beta_1) * layer.dweights\n",
    "        layer.bias_momentums = self.beta_1 * \\\n",
    "                               layer.bias_momentums + \\\n",
    "                               (1 - self.beta_1) * layer.dbiases\n",
    "        # Get corrected momentum\n",
    "        # self.iteration is 0 at first pass\n",
    "        # and we need to start with 1 here\n",
    "        weight_momentums_corrected = layer.weight_momentums / \\\n",
    "            (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        bias_momentums_corrected = layer.bias_momentums / \\\n",
    "            (1 - self.beta_1 ** (self.iterations + 1))\n",
    "        # Update cache with squared current gradients\n",
    "        layer.weight_cache = self.beta_2 * layer.weight_cache + \\\n",
    "            (1 - self.beta_2) * layer.dweights**2\n",
    "        layer.bias_cache = self.beta_2 * layer.bias_cache + \\\n",
    "            (1 - self.beta_2) * layer.dbiases**2\n",
    "        # Get corrected cache\n",
    "        weight_cache_corrected = layer.weight_cache / \\\n",
    "            (1 - self.beta_2 ** (self.iterations + 1))\n",
    "        bias_cache_corrected = layer.bias_cache / \\\n",
    "            (1 - self.beta_2 ** (self.iterations + 1))\n",
    "\n",
    "        # Vanilla SGD parameter update + normalization\n",
    "        # with square rooted cache\n",
    "        layer.weights += -self.current_learning_rate * \\\n",
    "                         weight_momentums_corrected / \\\n",
    "                         (np.sqrt(weight_cache_corrected) +\n",
    "                             self.epsilon)\n",
    "        layer.biases += -self.current_learning_rate * \\\n",
    "                         bias_momentums_corrected / \\\n",
    "                         (np.sqrt(bias_cache_corrected) +\n",
    "                             self.epsilon)\n",
    "\n",
    "    # Call once after any parameter updates\n",
    "    def post_update_params(self):\n",
    "        self.iterations += 1\n",
    "\n",
    "\n",
    "# Common loss class\n",
    "class Loss:\n",
    "\n",
    "    # Regularization loss calculation\n",
    "    def regularization_loss(self, layer):\n",
    "\n",
    "        # 0 by default\n",
    "        regularization_loss = 0\n",
    "\n",
    "        # L1 regularization - weights\n",
    "        # calculate only when factor greater than 0\n",
    "        if layer.weight_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l1 * \\\n",
    "                                   np.sum(np.abs(layer.weights))\n",
    "\n",
    "        # L2 regularization - weights\n",
    "        if layer.weight_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.weight_regularizer_l2 * \\\n",
    "                                   np.sum(layer.weights * \\\n",
    "                                          layer.weights)\n",
    "\n",
    "\n",
    "        # L1 regularization - biases\n",
    "        # calculate only when factor greater than 0\n",
    "        if layer.bias_regularizer_l1 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l1 * \\\n",
    "                                   np.sum(np.abs(layer.biases))\n",
    "\n",
    "        # L2 regularization - biases\n",
    "        if layer.bias_regularizer_l2 > 0:\n",
    "            regularization_loss += layer.bias_regularizer_l2 * \\\n",
    "                                   np.sum(layer.biases * \\\n",
    "                                          layer.biases)\n",
    "\n",
    "        return regularization_loss\n",
    "\n",
    "    # Calculates the data and regularization losses\n",
    "    # given model output and ground truth values\n",
    "    def calculate(self, output, y):\n",
    "\n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "\n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "\n",
    "        # Return loss\n",
    "        return data_loss\n",
    "\n",
    "\n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Probabilities for target values -\n",
    "        # only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[\n",
    "                range(samples),\n",
    "                y_true\n",
    "            ]\n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum(\n",
    "                y_pred_clipped * y_true,\n",
    "                axis=1\n",
    "            )\n",
    "\n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1:\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true / dvalues\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Softmax classifier - combined Softmax activation\n",
    "# and cross-entropy loss for faster backward step\n",
    "class Activation_Softmax_Loss_CategoricalCrossentropy():\n",
    "\n",
    "    # Creates activation and loss function objects\n",
    "    def __init__(self):\n",
    "        self.activation = Activation_Softmax()\n",
    "        self.loss = Loss_CategoricalCrossentropy()\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs, y_true):\n",
    "        # Output layer's activation function\n",
    "        self.activation.forward(inputs)\n",
    "        # Set the output\n",
    "        self.output = self.activation.output\n",
    "        # Calculate and return loss value\n",
    "        return self.loss.calculate(self.output, y_true)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # If labels are one-hot encoded,\n",
    "        # turn them into discrete values\n",
    "        if len(y_true.shape) == 2:\n",
    "            y_true = np.argmax(y_true, axis=1)\n",
    "\n",
    "        # Copy so we can safely modify\n",
    "        self.dinputs = dvalues.copy()\n",
    "        # Calculate gradient\n",
    "        self.dinputs[range(samples), y_true] -= 1\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Binary cross-entropy loss\n",
    "class Loss_BinaryCrossentropy(Loss):\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Calculate sample-wise loss\n",
    "        sample_losses = -(y_true * np.log(y_pred_clipped) +\n",
    "                          (1 - y_true) * np.log(1 - y_pred_clipped))\n",
    "        sample_losses = np.mean(sample_losses, axis=-1)\n",
    "\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "\n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -(y_true / clipped_dvalues -\n",
    "                         (1 - y_true) / (1 - clipped_dvalues)) / outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Mean Squared Error loss\n",
    "class Loss_MeanSquaredError(Loss):  # L2 loss\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Calculate loss\n",
    "        sample_losses = np.mean((y_true - y_pred)**2, axis=-1)\n",
    "\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "\n",
    "        # Gradient on values\n",
    "        self.dinputs = -2 * (y_true - dvalues) / outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Mean Absolute Error loss\n",
    "class Loss_MeanAbsoluteError(Loss):  # L1 loss\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "\n",
    "        # Calculate loss\n",
    "        sample_losses = np.mean(np.abs(y_true - y_pred), axis=-1)\n",
    "\n",
    "        # Return losses\n",
    "        return sample_losses\n",
    "\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "        # Number of outputs in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        outputs = len(dvalues[0])\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = np.sign(y_true - dvalues) / outputs\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs / samples\n",
    "\n",
    "\n",
    "# Create dataset\n",
    "X, y = sine_data()\n",
    "plt.plot(X, y)\n",
    "plt.show()\n",
    "\n",
    "# Create Dense layer with 1 input feature and 64 output values\n",
    "dense1 = Layer_Dense(1, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "# Create second Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 64 output values\n",
    "dense2 = Layer_Dense(64, 64)\n",
    "\n",
    "# Create ReLU activation (to be used with Dense layer):\n",
    "activation2 = Activation_ReLU()\n",
    "\n",
    "# Create third Dense layer with 64 input features (as we take output\n",
    "# of previous layer here) and 1 output value\n",
    "dense3 = Layer_Dense(64, 1)\n",
    "\n",
    "# Create Linear activation:\n",
    "activation3 = Activation_Linear()\n",
    "\n",
    "# Create loss function\n",
    "loss_function = Loss_MeanSquaredError()\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = Optimizer_Adam(learning_rate=0.005, decay=1e-3)\n",
    "\n",
    "\n",
    "# Accuracy precision for accuracy calculation\n",
    "# There are no really accuracy factor for regression problem,\n",
    "# but we can simulate/approximate it. We'll calculate it by checking\n",
    "# how many values have a difference to their ground truth equivalent\n",
    "# less than given precision\n",
    "# We'll calculate this precision as a fraction of standard deviation\n",
    "# of all the ground truth values\n",
    "accuracy_precision = np.std(y) / 250\n",
    "\n",
    "# Train in loop\n",
    "for epoch in range(10001):\n",
    "\n",
    "    # Perform a forward pass of our training data through this layer\n",
    "    dense1.forward(X)\n",
    "\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of first dense layer here\n",
    "    activation1.forward(dense1.output)\n",
    "\n",
    "    # Perform a forward pass through second Dense layer\n",
    "    # takes outputs of activation function\n",
    "    # of first layer as inputs\n",
    "    dense2.forward(activation1.output)\n",
    "\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of second dense layer here\n",
    "    activation2.forward(dense2.output)\n",
    "\n",
    "    # Perform a forward pass through third Dense layer\n",
    "    # takes outputs of activation function of second layer as inputs\n",
    "    dense3.forward(activation2.output)\n",
    "\n",
    "    # Perform a forward pass through activation function\n",
    "    # takes the output of third dense layer here\n",
    "    activation3.forward(dense3.output)\n",
    "\n",
    "    # Calculate the data loss\n",
    "    data_loss = loss_function.calculate(activation3.output, y)\n",
    "\n",
    "    # Calculate regularization penalty\n",
    "    regularization_loss = \\\n",
    "        loss_function.regularization_loss(dense1) + \\\n",
    "        loss_function.regularization_loss(dense2) + \\\n",
    "        loss_function.regularization_loss(dense3)\n",
    "\n",
    "    # Calculate overall loss\n",
    "    loss = data_loss + regularization_loss\n",
    "\n",
    "    # Calculate accuracy from output of activation2 and targets\n",
    "    # To calculate it we're taking absolute difference between\n",
    "    # predictions and ground truth values and compare if differences\n",
    "    # are lower than given precision value\n",
    "    predictions = activation3.output\n",
    "    accuracy = np.mean(np.absolute(predictions - y) <\n",
    "                       accuracy_precision)\n",
    "\n",
    "    if not epoch % 100:\n",
    "        print(f'epoch: {epoch}, ' +\n",
    "              f'acc: {accuracy:.3f}, ' +\n",
    "              f'loss: {loss:.3f} (' +\n",
    "              f'data_loss: {data_loss:.3f}, ' +\n",
    "              f'reg_loss: {regularization_loss:.3f}), ' +\n",
    "              f'lr: {optimizer.current_learning_rate}')\n",
    "\n",
    "    # Backward pass\n",
    "    loss_function.backward(activation3.output, y)\n",
    "    activation3.backward(loss_function.dinputs)\n",
    "    dense3.backward(activation3.dinputs)\n",
    "    activation2.backward(dense3.dinputs)\n",
    "    dense2.backward(activation2.dinputs)\n",
    "    activation1.backward(dense2.dinputs)\n",
    "    dense1.backward(activation1.dinputs)\n",
    "\n",
    "    # Update weights and biases\n",
    "    optimizer.pre_update_params()\n",
    "    optimizer.update_params(dense1)\n",
    "    optimizer.update_params(dense2)\n",
    "    optimizer.update_params(dense3)\n",
    "    optimizer.post_update_params()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_test, y_test = sine_data()\n",
    "\n",
    "dense1.forward(X_test)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "dense3.forward(activation2.output)\n",
    "activation3.forward(dense3.output)\n",
    "\n",
    "plt.plot(X_test, y_test)\n",
    "plt.plot(X_test, activation3.output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55a7e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnfs",
   "language": "python",
   "name": "nnfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
