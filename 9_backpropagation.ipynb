{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35618caa",
   "metadata": {},
   "source": [
    "# Chapter 9: Backpropagation\n",
    "\n",
    "Start with a simplified forward pass with just one neuron.\n",
    "\n",
    "Let’s backpropagate the ReLU function for a single neuron, then intend to minimize the output for this single neuron as a practice to show how we can leverage the chain rule with derivatives and partial derivatives.\n",
    "\n",
    "We will start by <b>minimizing this more basic output</b> before jumping to the full network and overall loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b28f55da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0\n"
     ]
    }
   ],
   "source": [
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "\n",
    "xw0 = x[0] * w[0]\n",
    "print(xw0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df959429",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-1.png' style='width: 70%'/><font color='gray'><i>The first input and weight multiplication.</i></font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f76e5102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0 2.0 6.0\n"
     ]
    }
   ],
   "source": [
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "print(xw0, xw1, xw2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdfb5fe",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-2.png' style='width: 70%'/><font color='gray'><i>Input and weight multiplication of all of the inputs.</i></font></center>\n",
    "\n",
    "Perform a sum of all weighted inputs with a bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "781f8435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b7973",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-3.png' style='width: 70%'/><font color='gray'><i>Weighted inputs and bias addition.</i></font></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93b0fe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e897955",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-4.png' style='width: 70%'/><font color='gray'><i>ReLU activation applied to the neuron output.</i></font></center>\n",
    "\n",
    "This is the full forward pass through a single neuron and a ReLU activation function.\n",
    "\n",
    "Let’s treat all of these chained functions as one big function which takes input values ($x$), weights ($w$), and bias ($b$), as inputs, and outputs ($y$).\n",
    "\n",
    "This big function consists of <b>3 chained functions</b> in total: a multiplication of input values and weights, a sum of these values and bias, as well as a $max$ function as the ReLU activation.\n",
    "\n",
    "\n",
    "## 9.1. Derivative of activation function\n",
    "\n",
    "Backpropagate our gradients by calculating derivatives and partial derivatives w.r.t each of our parameters and inputs.\n",
    "\n",
    "The big function in the context of our neural network, can be loosely interpreted as:\n",
    "\n",
    "$$\n",
    "\\text{ReLU} \\Big( \\sum[ \\ \\text{input} \\cdot \\text{weights} \\ ] + \\text{bias} \\Big)\n",
    "$$\n",
    "\n",
    "Or in the form that matches code more precisely as:\n",
    "\n",
    "$$\n",
    "\\text{ReLU} \\Big( x_0 w_0 + x_1 w_1 + x_2 w_2 + b  \\Big)\n",
    "$$\n",
    "\n",
    "Rewrite the function to the form that will allow us to determine how to calculate the derivatives more easily:\n",
    "\n",
    "$$\n",
    "y = \\text{ReLU} \\Big( sum \\big( mul(x_0 , w_0 ), mul(x_1 , w_1 ), mul(x_2 , w_2 ), b \\big) \\Big)\n",
    "$$\n",
    "\n",
    "Calculate the partial derivative with respect to $w_0$.\n",
    "\n",
    "$$\n",
    "\\frac{∂}{∂x_0} \\bigg[ \\text{ReLU} \\Big( sum \\big( mul(x_0 , w_0 ), mul(x_1 , w_1 ), mul(x_2 , w_2 ), b \\big) \\Big)  \\bigg]\n",
    "$$\n",
    "\n",
    "The derivative with respect to the layer’s inputs is not used to update any parameters. It is used to chain to another layer.\n",
    "\n",
    "We can repeat this to calculate all of the other remaining impacts.\n",
    "\n",
    "We want to know the impact of a given weight or bias on the loss. Thus, we have to calculate the derivative of the loss function and apply the chain rule with the derivatives of all activation functions and neurons in all of the consecutive layers.\n",
    "\n",
    "Assume that our neuron receives a gradient of $1$ from the next layer (for demonstration purposes), a value of $1$ won't change the values, that means we can more easily show all of the processes. The color red is used for derivatives.\n",
    "\n",
    "<center><img src='./image/9-5.png' style='width: 70%'/><font color='gray'><i>Initial gradient (received during backpropagation).</i></font></center>\n",
    "\n",
    "Recall the derivative of $ReLU()$ w.r.t its input:\n",
    "\n",
    "$$\n",
    "f(x) = max(x,0) \\quad \\to \\quad \\frac{d}{dx} f(x) = 1 (x>0)\n",
    "$$\n",
    "\n",
    "The input value to the $ReLU$ function is $6$, so the derivative equals $1$.\n",
    "\n",
    "We have to use the chain rule and multiply this derivative with the derivative received from the next layer (which is 1 for the purpose of this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce3fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "\n",
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "\n",
    "# Backward pass\n",
    "# The derivative from the next layer\n",
    "dvalue = 1.0\n",
    "\n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * (1. if z > 0 else 0.)\n",
    "print(drelu_dz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb864c3",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-6.png' style='width: 70%'/><font color='gray'><i>Derivative of the $ReLU$ function and chain rule.</i></font></center>\n",
    "\n",
    "This results with the derivative of 1 :\n",
    "\n",
    "<center><img src='./image/9-7.png' style='width: 70%'/><font color='gray'><i>ReLU and chain rule gradient.</i></font></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2bec78",
   "metadata": {},
   "source": [
    "## 9.2. Derivative of a sum of the weighted inputs and bias\n",
    "\n",
    "Moving backward through our neural network, a sum of the weighted inputs and bias comes immediately before we perform the activation function.\n",
    "\n",
    "Thus, we must calculate the partial derivative of the sum function, then, using the chain rule, multiply this by the partial derivative of the subsequent, outer, function, which is $ReLU$.\n",
    "\n",
    "Recall the partial derivative of the sum operation is always 1:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x,y) = x+y \\quad \\to \\quad & \\frac{∂}{∂x} f(x,y) = 1\\\\\n",
    "& \\frac{∂}{∂y} f(x,y) = 1 \\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c276ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0 1.0 1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# Forward pass\n",
    "x = [1.0, -2.0, 3.0] # input values\n",
    "w = [-3.0, -1.0, 2.0] # weights\n",
    "b = 1.0 # bias\n",
    "\n",
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding weighted inputs and a bias\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "\n",
    "# Backward pass\n",
    "# The derivative from the next layer\n",
    "dvalue = 1.0\n",
    "\n",
    "# Derivative of ReLU and the chain rule\n",
    "drelu_dz = dvalue * (1. if z > 0 else 0.)\n",
    "print(drelu_dz)\n",
    "\n",
    "# Partial derivatives of the multiplication, the chain rule\n",
    "dsum_dxw0 = 1\n",
    "dsum_dxw1 = 1\n",
    "dsum_dxw2 = 1\n",
    "dsum_db = 1\n",
    "drelu_dxw0 = drelu_dz * dsum_dxw0\n",
    "drelu_dxw1 = drelu_dz * dsum_dxw1\n",
    "drelu_dxw2 = drelu_dz * dsum_dxw2\n",
    "drelu_db = drelu_dz * dsum_db\n",
    "\n",
    "print(drelu_dxw0, drelu_dxw1, drelu_dxw2, drelu_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7db60",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-8.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the sum function w.r.t. the first weighted input.</i></font></center>\n",
    "\n",
    "This results with a partial derivative of 1 again:\n",
    "\n",
    "<center><img src='./image/9-9.png' style='width: 70%'/><font color='gray'><i>The sum and chain rule gradient for the first weighted input.</i></font></center>\n",
    "\n",
    "Perform the same operation with the next weighted input:\n",
    "\n",
    "<center><img src='./image/9-10.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the sum function w.r.t. the second weighted input.</i></font></center>\n",
    "\n",
    "Which results with the next calculated partial derivative:\n",
    "\n",
    "<center><img src='./image/9-11.png' style='width: 70%'/><font color='gray'><i>The sum and chain rule gradient (for the second weighted input).</i></font></center>\n",
    "\n",
    "And the last weighted input:\n",
    "\n",
    "<center><img src='./image/9-12.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the sum function w.r.t. the third weighted input.</i></font></center>\n",
    "\n",
    "<center><img src='./image/9-13.png' style='width: 70%'/><font color='gray'><i>The sum and chain rule gradient (for the third weighted input).</i></font></center>\n",
    "\n",
    "Then the bias:\n",
    "\n",
    "<center><img src='./image/9-14.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the sum function w.r.t. the bias.</i></font></center>\n",
    "\n",
    "<center><img src='./image/9-15.png' style='width: 70%'/><font color='gray'><i>The sum and chain rule gradient (for the bias).</i></font></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd73a2",
   "metadata": {},
   "source": [
    "## 9.3. Derivative of the multiplication of weights and inputs\n",
    "\n",
    "The derivative for a product is whatever the input is being multiplied by.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x,y) = x \\cdot y \\quad \\to \\quad & \\frac{∂}{∂x} f(x,y) = y \\\\\n",
    "& \\frac{∂}{∂y} f(x,y) = x \\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "246f2955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.0 1.0 -1.0 -2.0 2.0 3.0\n"
     ]
    }
   ],
   "source": [
    "# Partial derivatives of the multiplication, the chain rule\n",
    "dmul_dx0 = w[0]\n",
    "dmul_dx1 = w[1]\n",
    "dmul_dx2 = w[2]\n",
    "dmul_dw0 = x[0]\n",
    "dmul_dw1 = x[1]\n",
    "dmul_dw2 = x[2]\n",
    "drelu_dx0 = drelu_dxw0 * dmul_dx0\n",
    "drelu_dw0 = drelu_dxw0 * dmul_dw0\n",
    "drelu_dx1 = drelu_dxw1 * dmul_dx1\n",
    "drelu_dw1 = drelu_dxw1 * dmul_dw1\n",
    "drelu_dx2 = drelu_dxw2 * dmul_dx2\n",
    "drelu_dw2 = drelu_dxw2 * dmul_dw2\n",
    "\n",
    "print(drelu_dx0, drelu_dw0, drelu_dx1, drelu_dw1, drelu_dx2, drelu_dw2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30d9543",
   "metadata": {},
   "source": [
    "<center><img src='./image/9-16.png' style='width: 70%'/><font color='gray'><i>Partial derivative of the multiplication function w.r.t. the first input.</i></font></center>\n",
    "\n",
    "<center><img src='./image/9-17.png' style='width: 70%'/><font color='gray'><i>The multiplication and chain rule gradient (for the first input).</i></font></center>\n",
    "\n",
    "The complete set of the activated neuron’s partial derivatives with respect to the inputs, weights and a bias.\n",
    "\n",
    "<center><img src='./image/9-18.png' style='width: 70%'/><font color='gray'><i>Complete backpropagation graph.</i></font></center>\n",
    "\n",
    "Recall the equation from the beginning:\n",
    "\n",
    "$$\n",
    "\\frac{∂}{∂x_0} \\bigg[ \\text{ReLU} \\Big( sum \\big( mul(x_0 , w_0 ), mul(x_1 , w_1 ), mul(x_2 , w_2 ), b \\big) \\Big)  \\bigg]\n",
    "= \\frac{d \\text{ReLU} }{d sum()} \\cdot \\frac{∂ sum() }{∂ mul(x_0 , w_0 )} \\cdot \\frac{∂ mul(x_0 , w_0 )}{∂x_0}\n",
    "$$\n",
    "\n",
    "The partial derivative of a neuron’s function, with respect to the weight, is the input related to this weight, and, with respect to the input, is the related weight. The partial derivative of the neuron’s function with respect to the bias is always 1.\n",
    "\n",
    "\n",
    "## 9.4. Update weight and bias to decrease output\n",
    "\n",
    "All partial derivatives above combined into a vector, make up our gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a3fd683",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = [drelu_dx0, drelu_dx1, drelu_dx2] # gradients on inputs\n",
    "dw = [drelu_dw0, drelu_dw1, drelu_dw2] # gradients on weights\n",
    "db = drelu_db # gradient on bias...just 1 bias here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff74a24",
   "metadata": {},
   "source": [
    "For this single neuron example, we won't need our $dx$.\n",
    "\n",
    "We will apply these gradients to the weights to hopefully minimize the output.\n",
    "\n",
    "We apply a negative fraction to this gradient to decrease the final output value, as the gradient shows the direction of the steepest ascent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "431c089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.0, -1.0, 2.0] 1.0\n"
     ]
    }
   ],
   "source": [
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39725f35",
   "metadata": {},
   "source": [
    "Apply a fraction of the gradients to these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19b25533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.001, -0.998, 1.997] 0.999\n"
     ]
    }
   ],
   "source": [
    "w[0] += -0.001 * dw[0]\n",
    "w[1] += -0.001 * dw[1]\n",
    "w[2] += -0.001 * dw[2]\n",
    "b += -0.001 * db\n",
    "print(w, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412137f7",
   "metadata": {},
   "source": [
    "We slightly changed the weights and bias in such a way to decrease the output intelligently.\n",
    "\n",
    "Do another forward pass to see the effects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b01d73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.985\n"
     ]
    }
   ],
   "source": [
    "# Multiplying inputs by weights\n",
    "xw0 = x[0] * w[0]\n",
    "xw1 = x[1] * w[1]\n",
    "xw2 = x[2] * w[2]\n",
    "\n",
    "# Adding\n",
    "z = xw0 + xw1 + xw2 + b\n",
    "\n",
    "# ReLU activation function\n",
    "y = max(z, 0)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dcfaee",
   "metadata": {},
   "source": [
    "We've successfully decreased this neuron's output from $6.000$ to $5.985$.\n",
    "\n",
    "It does not make sense to decrease the neuron's output in a real neural network. We do this as a simpler exercise.\n",
    "\n",
    "We want to decrease the loss value, which is the last calculation in the chain of calculations during the forward pass, and it's the first one to calculate the gradient during the backpropagation.\n",
    "\n",
    "## 9.5. List of samples and a layer of neurons\n",
    "\n",
    "### A singular sample\n",
    "\n",
    "A single neuron of the current layer connects to all of them — they all receive the output of this neuron.\n",
    "\n",
    "What happen during backpropagation?\n",
    "\n",
    "Each neuron from the next layer will return a partial derivative of its function w.r.t all of its inputs.\n",
    "\n",
    "The neuron in the current layer will receive a vector consisting of these derivatives.\n",
    "\n",
    "To continue backpropagation, we need to sum this vector to be a singular value for a singular neuron.\n",
    "\n",
    "For a layer of neurons, it'll be a list of these vectors, or a 2D array.\n",
    "\n",
    "To apply the chain rule, we need to multiply them by the gradient from the subsequent function.\n",
    "\n",
    "We should perform a sum along the inputs - the first input to all of the neurons, the second input, and so on. So we have to sum columns.\n",
    "\n",
    "The array of partial derivatives w.r.t all of the inputs equals the array of weights.\n",
    "\n",
    "Since the array is transposed, we need to sum its rows instead of columns.\n",
    "\n",
    "Then we calculate the gradient for the next layer in backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ecb92a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44  0.44  0.44]\n",
      " [-0.38 -0.38 -0.38]\n",
      " [-0.07 -0.07 -0.07]\n",
      " [ 1.37  1.37  1.37]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# a vector of 1s\n",
    "dvalues = np.array([[1., 1., 1.]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91 , 0.26, -0.5],\n",
    "                    [-0.26, -0.27 , 0.17, 0.87]]).T\n",
    "\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dx0 = sum(weights[0]) * dvalues[0]\n",
    "dx1 = sum(weights[1]) * dvalues[0]\n",
    "dx2 = sum(weights[2]) * dvalues[0]\n",
    "dx3 = sum(weights[3]) * dvalues[0]\n",
    "\n",
    "# the gradient of the neuron function with respect to inputsm\n",
    "dinputs = np.array([dx0, dx1, dx2, dx3])\n",
    "\n",
    "print(dinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88033c9f",
   "metadata": {},
   "source": [
    "We can achieve the same result by using the `np.dot` function. \n",
    "\n",
    "Recall, we have one partial derivative for each neuron and multiply it by the neuron’s partial derivative with respect to its input.\n",
    "\n",
    "Then, multiply each of these gradients with each of the partial derivatives that are related to this neuron’s inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9b617a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.44 -0.38 -0.07  1.37]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# a vector of 1s\n",
    "dvalues = np.array([[1., 1., 1.]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5 ],\n",
    "                    [-0.26, -0.27, 0.17, 0.87 ]]).T\n",
    "\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dinputs = np.dot(dvalues[ 0 ], weights.T)\n",
    "\n",
    "print (dinputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367bb70",
   "metadata": {},
   "source": [
    "### A batch of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af991f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.44 -0.38 -0.07  0.5 ]\n",
      " [ 0.88 -0.76 -0.14  1.  ]\n",
      " [ 1.32 -1.14 -0.21  1.5 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer\n",
    "# for the purpose of this example we're going to use\n",
    "# an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0]]).T\n",
    "\n",
    "# sum weights of given input\n",
    "# and multiply by the passed in gradient for this neuron\n",
    "dinputs = np.dot(dvalues, weights.T)\n",
    "\n",
    "print (dinputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8574b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5  0.5  0.5]\n",
      " [20.1 20.1 20.1]\n",
      " [10.9 10.9 10.9]\n",
      " [ 4.1  4.1  4.1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer for the purpose of this example \n",
    "# We're going to use an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of inputs - samples\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                [2., 5., -1., 2],\n",
    "                [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# Sum weights of given input and multiply by the passed in gradient for this neuron\n",
    "dweights = np.dot(inputs.T, dvalues)\n",
    "\n",
    "print(dweights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92599710",
   "metadata": {},
   "source": [
    "For the biases and derivatives with respect to them, the derivatives come from the sum operation and always equal 1, multiplied by the incoming gradients to apply the chain rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7593dcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 6. 6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer for the purpose of this example\n",
    "# we're going to use an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# One bias for each neuron biases are the row vector with a shape (1, neurons)\n",
    "biases = np.array([[2, 3, 0.5]])\n",
    "\n",
    "# dbiases - sum values, do this over samples (first axis), keepdims\n",
    "# since this by default will produce a plain list - we explained this in the chapter 4\n",
    "dbiases = np.sum(dvalues, axis = 0 , keepdims = True )\n",
    "\n",
    "print(dbiases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d12e4c8",
   "metadata": {},
   "source": [
    "### Derivative of the ReLU function\n",
    "\n",
    "It equals 1 if the input is greater than 0 and 0 otherwise.\n",
    "\n",
    "The layer passes its outputs through the $ReLU()$ activation during the forward pass.\n",
    "\n",
    "For the backward pass, $ReLU()$ receives a gradient of the same shape.\n",
    "\n",
    "The derivative of the ReLU function will form an array of the same shape, filled with 1 when the related input is greater than 0, and 0 otherwise.\n",
    "\n",
    "To apply the chain rule, we need to multiply this array with the gradients of the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29a289f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0]\n",
      " [1 0 0 1]\n",
      " [0 1 1 0]]\n",
      "[[ 1  2  0  0]\n",
      " [ 5  0  0  8]\n",
      " [ 0 10 11  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example layer output (4 neurons)\n",
    "z = np.array([[1, 2, -3, -4],\n",
    "              [2, -7, -1, 3],\n",
    "              [-1, 2, 5, -1]])\n",
    "\n",
    "dvalues = np.array([[1, 2, 3, 4],\n",
    "                    [5, 6, 7, 8],\n",
    "                    [9, 10, 11, 12]])\n",
    "\n",
    "# ReLU activation's derivative\n",
    "drelu = np.zeros_like(z)\n",
    "drelu[z > 0] = 1\n",
    "print(drelu)\n",
    "\n",
    "# The chain rule\n",
    "drelu *= dvalues\n",
    "\n",
    "print(drelu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb49f7",
   "metadata": {},
   "source": [
    "We can simplify this operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa15faa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  0  0]\n",
      " [ 5  0  0  8]\n",
      " [ 0 10 11  0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example layer output\n",
    "z = np.array([[1, 2, -3, -4],\n",
    "              [2, -7, -1, 3],\n",
    "              [-1, 2, 5, -1]])\n",
    "\n",
    "dvalues = np.array([[1, 2, 3, 4],\n",
    "                    [5, 6, 7, 8],\n",
    "                    [9, 10, 11, 12]])\n",
    "\n",
    "# ReLU activation's derivative with the chain rule applied\n",
    "drelu = dvalues.copy()    # ensures that we don't modify it during the ReLU derivative calculation.\n",
    "drelu[z <= 0] = 0\n",
    "\n",
    "print(drelu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b632853d",
   "metadata": {},
   "source": [
    "Let’s combine the forward and backward pass of a single neuron with a full layer and batch-based partial derivatives. We’ll minimize ReLU’s output, once again, only for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5b09f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.179515   0.5003665 -0.262746 ]\n",
      " [ 0.742093  -0.9152577 -0.2758402]\n",
      " [-0.510153   0.2529017  0.1629592]\n",
      " [ 0.971328  -0.5021842  0.8636583]]\n",
      "[[1.98489  2.997739 0.497389]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Passed in gradient from the next layer for the purpose of this example\n",
    "# We're going to use an array of an incremental gradient values\n",
    "dvalues = np.array([[1., 1., 1.],\n",
    "                    [2., 2., 2.],\n",
    "                    [3., 3., 3.]])\n",
    "\n",
    "# We have 3 sets of inputs - samples\n",
    "inputs = np.array([[1, 2, 3, 2.5],\n",
    "                   [2., 5., -1., 2],\n",
    "                   [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "# We have 3 sets of weights - one set for each neuron\n",
    "# we have 4 inputs, thus 4 weights\n",
    "# recall that we keep weights transposed\n",
    "weights = np.array([[0.2, 0.8, -0.5, 1],\n",
    "                    [0.5, -0.91, 0.26, -0.5],\n",
    "                    [-0.26, -0.27, 0.17, 0.87]]).T\n",
    "\n",
    "# One bias for each neuron\n",
    "# biases are the row vector with a shape (1, neurons)\n",
    "biases = np.array([[2, 3, 0.5]])\n",
    "\n",
    "# Forward pass\n",
    "layer_outputs = np.dot(inputs, weights) + biases # Dense layer\n",
    "relu_outputs = np.maximum(0, layer_outputs) # ReLU activation\n",
    "\n",
    "# Let's optimize and test backpropagation here\n",
    "# ReLU activation - simulates derivative with respect to input values\n",
    "# from next layer passed to current layer during backpropagation\n",
    "drelu = relu_outputs.copy()\n",
    "drelu[layer_outputs <= 0] = 0\n",
    "\n",
    "# Dense layer\n",
    "# dinputs - multiply by weights\n",
    "dinputs = np.dot(drelu, weights.T)\n",
    "\n",
    "# dweights - multiply by inputs\n",
    "dweights = np.dot(inputs.T, drelu)\n",
    "\n",
    "# dbiases - sum values, do this over samples (first axis), keepdims\n",
    "# since this by default will produce a plain list - we explained this in the chapter 4\n",
    "dbiases = np.sum(drelu, axis = 0 , keepdims = True)\n",
    "\n",
    "# Update parameters\n",
    "weights += - 0.001 * dweights\n",
    "biases += - 0.001 * dbiases\n",
    "\n",
    "print(weights)\n",
    "print(biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072a2903",
   "metadata": {},
   "source": [
    "Update the dense layer and ReLU activation code with a `backward` method (for backpropagation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49da7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dense layer\n",
    "class Layer_Dense :\n",
    "    # Layer initialization\n",
    "    def __init__ (self, inputs, neurons):\n",
    "        self.weights = 0.01 * np.random.randn(inputs, neurons)\n",
    "        self.biases = np.zeros((1, neurons))\n",
    "\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        # To remember what the inputs were (needed when calculating the partial derivative w.r.t weights during backpropagation)\n",
    "        self.inputs = inputs\n",
    "        \n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Gradients on parameters\n",
    "        self.dweights = np.dot(self.inputs.T, dvalues)\n",
    "        self.dbiases = np.sum(dvalues, axis = 0, keepdims = True)\n",
    "\n",
    "        # Gradient on values\n",
    "        self.dinputs = np.dot(dvalues, self.weights.T)\n",
    "\n",
    "\n",
    "# ReLU activation\n",
    "class Activation_ReLU :\n",
    "    # Forward pass\n",
    "    def forward(self, inputs):\n",
    "        # Remember input values\n",
    "        self.inputs = inputs\n",
    "        self.output = np.maximum(0, inputs)\n",
    "\n",
    "    # Backward pass\n",
    "    def backward(self, dvalues):\n",
    "        # Since we need to modify the original variable, let's make a copy of the values first\n",
    "        self.dinputs = dvalues.copy()\n",
    "\n",
    "        # Zero gradient where input values were negative\n",
    "        self.dinputs[self.inputs <= 0 ] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c57d53",
   "metadata": {},
   "source": [
    "## 9.6. Categorical Cross-Entropy loss derivative\n",
    "\n",
    "As stated in chapter 5, the Categorical Cross-Entropy loss function's formula is:\n",
    "\n",
    "$$\n",
    "L_i = \\ \\text{log} \\ \\big(  \\hat{y}_{i,k} \\big) \\qquad \\text{where }  k \\text{ is an index of \"true\" probability}\n",
    "$$\n",
    "\n",
    "where $L_i$ denotes sample loss value, $i^{th}$ sample in a set, $k$ - index of the target label (ground-true label), $y$ - target values and $\\hat y$ predicted values.\n",
    "\n",
    "All we need is the output of the Softmax activation function at the index of the correct class.\n",
    "\n",
    "To calculate partial derivatives with respect to each of the inputs, we need an equation that takes all of them as parameters, thus the choice to use the full equation.\n",
    "\n",
    "For the purpose of the derivative calculation, we use the full equation mentioned back in chapter 5:\n",
    "\n",
    "$$\n",
    "L_i = - \\sum_j y_{i,j} \\ \\text{log} \\ \\big(  \\hat{y}_{i,j} \\big)\n",
    "$$\n",
    "\n",
    "where $L_i$ denotes sample loss value, $i^{th}$ sample in a set, $j$ - label/output index, $y$ - target values and $\\hat y$ predicted values.\n",
    "\n",
    "Recall,\n",
    "\n",
    "$$\n",
    "f(x) = \\text{log} \\big( h(x) \\big) \\quad \\to \\quad f'(x) = \\frac{1}{h(x)} \\cdot h'(x)\\\\\n",
    "f(x) = \\text{log} (x) \\quad \\to \\quad \\frac{d}{dx} f(x) = \\frac{d}{dx} \\text{log} (x) =   \\frac{1}{x} \\cdot \\frac{d}{dx} x = \\frac{1}{x} \\cdot 1 = \\frac{1}{x}\n",
    "$$\n",
    "\n",
    "First, let’s define the gradient equation as the partial derivative of the loss function w.r.t each of its inputs.\n",
    "\n",
    "$$\n",
    "\\frac{∂ L_i}{∂ \\hat{y}_{i,j}} = \\frac{∂ }{∂ \\hat{y}_{i,j}} \\Big[  - \\sum_j y_{i,j} \\ \\text{log} \\ \\big(  \\hat{y}_{i,j} \\big)  \\Big] =   - \\sum_j y_{i,j} \\cdot \\frac{∂ }{∂ \\hat{y}_{i,j}}  \\text{log} \\big(  \\hat{y}_{i,j} \\big)  =   - \\sum_j y_{i,j} \\cdot \\frac{1}{\\hat{y}_{i,j}} \\cdot \\frac{∂ }{∂ \\hat{y}_{i,j}}  \\hat{y}_{i,j}  =   - \\sum_j y_{i,j} \\cdot \\frac{1}{\\hat{y}_{i,j}} \\cdot 1  =  - \\sum_j \\frac{y_{i,j}}{\\hat{y}_{i,j}}  =  - \\frac{y_{i,j}}{\\hat{y}_{i,j}}\n",
    "$$\n",
    "\n",
    "The derivative of this loss function with respect to its inputs (predicted values at the $i^{th}$ sample, since we are interested in a gradient with respect to the predicted values) equals the negative ground-truth vector, divided by the vector of the predicted values (which is also the output vector of the softmax function).\n",
    "\n",
    "\n",
    "## 9.7. Categorical Cross-Entropy loss derivative code implementation\n",
    "\n",
    "Add a backward method to the `Loss_CategoricalCrossentropy` class, and pass the array of predictions and the array of true values into it and calculate the negated division of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e71c8050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common loss class\n",
    "class Loss :\n",
    "    \n",
    "    # Calculates the data and regularization losses given model output and ground truth values\n",
    "    def calculate ( self , output , y ):\n",
    "        \n",
    "        # Calculate sample losses\n",
    "        sample_losses = self.forward(output, y)\n",
    "        \n",
    "        # Calculate mean loss\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        \n",
    "        # Return loss\n",
    "        \n",
    "        return data_loss\n",
    "\n",
    "    \n",
    "# Cross-entropy loss\n",
    "class Loss_CategoricalCrossentropy(Loss):\n",
    "    \n",
    "    # Forward pass\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \n",
    "        # Number of samples in a batch\n",
    "        samples = len(y_pred)\n",
    "        \n",
    "        # Clip data to prevent division by 0\n",
    "        # Clip both sides to not drag mean towards any value\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
    "        \n",
    "        # Probabilities for target values - only if categorical labels\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[ range(samples), y_true]\n",
    "        \n",
    "        # Mask values - only for one-hot encoded labels\n",
    "        elif len(y_true.shape) == 2:\n",
    "            correct_confidences = np.sum( y_pred_clipped*y_true, axis=1)\n",
    "        \n",
    "        # Losses\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        \n",
    "        return negative_log_likelihoods\n",
    "\n",
    "    # Backward pass\n",
    "    def backward (self, dvalues, y_true):\n",
    "\n",
    "        # Number of samples\n",
    "        samples = len(dvalues)\n",
    "\n",
    "        # Number of labels in every sample\n",
    "        # We'll use the first sample to count them\n",
    "        labels = len(dvalues[0])\n",
    "\n",
    "        # If labels are sparse, turn them into one-hot vector\n",
    "        if len(y_true.shape) == 1 :\n",
    "            y_true = np.eye(labels)[y_true]\n",
    "\n",
    "        # Calculate gradient\n",
    "        self.dinputs = -y_true/dvalues\n",
    "\n",
    "        # Normalize gradient\n",
    "        self.dinputs = self.dinputs/samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b4cc4",
   "metadata": {},
   "source": [
    "Optimizers sum all of the gradients related to each weight and bias before multiplying them by the learning rate (or some other factor). This means that the more samples we have in a dataset, the more gradient sets we’ll receive at this step, and the bigger this sum will become. As a consequence, we’ll have to adjust the learning rate according to each set of samples.\n",
    "\n",
    "To solve this problem, we can divide all of the gradients by the number of samples. A sum of elements divided by a count of them is their mean value (the optimizer will perform the sum). Thus, we will effectively normalize the gradients and make their sum’s magnitude invariant to the number of samples.\n",
    "\n",
    "\n",
    "## 9.8. Softmax activation derivative\n",
    "\n",
    "The partial derivative of the Softmax function is a bit more complicated task than the derivative of the Categorical Cross-Entropy loss.\n",
    "\n",
    "Recall, the equation of the Softmax activation function and define the derivative:\n",
    "\n",
    "$$\n",
    "S_{i.j} = \\frac{e^{z_{i,j}}}{\\sum_{l=1}^{L} e^{z_{i,l}}} \\quad \\to \\quad \\frac{∂ S_{i,j}}{∂z_{i.k}} = \\frac{∂ \\frac{e^{z_{i,j}}}{\\sum_{l=1}^{L} e^{z_{i,l}}}}{∂z_{i.k}}\n",
    "$$\n",
    "\n",
    "where $S_{i_j}$ denotes $j^{th}$ Softmax’s output of $i^{th}$ sample, $z$ - input array which is a list of input vectors (output vectors from the previous layer), $z_{i,j}$ - $j^{th}$ Softmax’s input of $i^{th}$ sample, $L$ - number of inputs, $z_{i,k}$ - $k^{th}$ Softmax’s input of $i^{th}$ sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89358653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnfs",
   "language": "python",
   "name": "nnfs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
